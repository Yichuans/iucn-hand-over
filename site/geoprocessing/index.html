



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-0.17.2, mkdocs-material-2.5.3">
    
    
      
        <title>Geoprocessing - Handover World Heritage GIS</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.aa3de92b.css">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <a href="#introduction" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="Handover World Heritage GIS" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                Handover World Heritage GIS
              </span>
              <span class="md-header-nav__topic">
                Geoprocessing
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </span>
    Handover World Heritage GIS
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../world-heritage-database/" title="Database" class="md-nav__link">
      Database
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../comparative-analysis/" title="Comparative analysis" class="md-nav__link">
      Comparative analysis
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
      
    
    
    <a href="./" title="Geoprocessing" class="md-nav__link md-nav__link--active">
      Geoprocessing
    </a>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../world-heritage-knowledge-lab/" title="World Heritage Analyses" class="md-nav__link">
      World Heritage Analyses
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../world-heritage-outlook/" title="World Heritage Outlook" class="md-nav__link">
      World Heritage Outlook
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../datasheet/" title="Datasheet" class="md-nav__link">
      Datasheet
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../presentation/" title="Presentation" class="md-nav__link">
      Presentation
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../folder-structure/" title="Folder structure" class="md-nav__link">
      Folder structure
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="introduction">Introduction</h1>
<p>This section explains the <em>technical</em> side of my work, on analysis, maps and automation. </p>
<p>The reason why much of my time has gone into the development, improvement and maintenance of the scripts is simple - next time the same task is requested again, I have an existing method, or previously working solution, that could be re-used or easily adapted. This saves time and increases productivity</p>
<p>Wherever possible, I try to automate. In some cases, this may represents a poor use of time, i.e., doing it manually step by step may be quicker. Automation for one-off tasks may seem over-engineering, I would argue, however, any time spent on making a tool, or spent on mastering a potentially more productive tool is a justified investment with good productivity return in the long term. </p>
<p>For example, the different implementations of the comparative analysis have led to a reduced workload significantly. See below a graph depicting the amount of days to do the spatial overlay between the plethora of datasets and new nominations. This frees time for species richness, irreplaceability, improved maps, just to name a few.</p>
<p><img alt="time-spent-ca" src="../img/ca-time.png" /></p>
<p>Some of the tasks share similar technical challenges. Especially for frequent, recurring tasks, it is imperative to develop libraries or templates to minimise repetitive work, and that more time can be made available for more creative tasks and increased productivity. </p>
<h1 id="geoprocessing-libraries">Geoprocessing libraries</h1>
<p>The geoprocessing library  (located at <code>geoprocessing\library</code>) is a collection of commonly used functions. They evolve from dedicated solutions to tasks that share technical challenges in common. Most of them relate to spatial analyses, usually involving the use of <code>arcpy</code> library in ArcGIS.</p>
<p>In order to use this library, it must be visible to Python. The easiest way to achieving this is to set the system variable <code>PYTHONPATH</code> to include the <code>geoprocessing\library</code> path.</p>
<p>The library consists the follow components:</p>
<ol>
<li><a href="https://github.com/Yichuans/geoprocessing/blob/master/library/Yichuan10.py">Yichuan10.py</a> holds a collection of mostly utility functions (with a humble and long history, starting with ArcGIS version 10, which still reflects in the name of the library). Commonly used functions include the two <a href="https://www.thecodeship.com/patterns/guide-to-python-function-decorators/">'decorators'</a> to track memory usage, and time required for executing functions, and the <code>GetUniqueValuesFromFeatureLayer_mk2</code> function that finds unique values in any given field in a feature layer. The latter simplifies the common task of finding unique IDs, such as the <code>wdpaid</code> for the WDPA or <code>id_no</code> for Red List.</li>
</ol>
<pre><code class="python">
def GetUniqueValuesFromFeatureLayer_mk2(inputFc, inputField):
    &quot;&quot;&quot;&lt;string&gt;, &lt;string&gt; -&gt; pythonList
    can be both feature class or feature layer&quot;&quot;&quot;
    pySet = set()
    with arcpy.da.SearchCursor(inputFc, inputField) as cursor:
        for row in cursor:
            pySet.add(row[0])

    return list(pySet)

</code></pre>

<ol>
<li>
<p><a href="https://github.com/Yichuans/geoprocessing/blob/master/library/YichuanDB.py">YichuanDB.py</a> includes a number of useful functions to connect and manipulate PostgreSQL databases. For the most part, I use the <code>ConnectionParameter</code> class to simplify making connections to the database. Convenient functions like <code>clean_view</code> enables testing and debugging of the comparative analysis, which relies on the direct access and manipulation of data in the database.</p>
</li>
<li>
<p><a href="https://github.com/Yichuans/geoprocessing/blob/master/library/YichuanM.py">YichuanM.py</a> evolved from a suite of utility functions originally resided in the <code>Yichuan10.py</code> that specifically aimed at tasks relating to the automatic/batch production of maps (use pre-authored map template, to be discussed in detail in the <a href="#Map-batch-template">map batch template</a>)</p>
</li>
<li>
<p><a href="https://github.com/Yichuans/geoprocessing/blob/master/library/YichuanRAS.py">YichuanRAS.py</a> contains functions that manipulates raster datasets (most of them are for vectors) using both the <code>arcpy</code> but also <code>gdal</code>, an open source but lower-level alternative. Many of the functions here underpin the <a href="../world-heritage-knowledge-lab/#links-to-prototypes">analysis of landcover change</a>, which implemented the calculation of zonal statistics using <code>gdal</code></p>
</li>
<li>
<p><a href="https://github.com/Yichuans/geoprocessing/blob/master/library/YichuanSR.py">YichuanSR.py</a> has many utility functions relating to coordinate systems. For example, the function <code>get_desirable_sr</code> tries to guess a best optimal coordinate system based on the geometry (the input expects <code>arcpy.Geometry</code> or <code>arcpy.Extent</code> object). This is useful to identify the most appropriate coordinate system when automating map productions - it's never a good idea to use a global coordinate system for a site scale map - use a specific UTM instead! NB. This function pre-dates a similar <a href="http://desktop.arcgis.com/en/arcmap/10.3/tools/cartography-toolbox/calculate-utm-zone.htm">CalculateUTMZone</a> function, now included by default in newer releases of ArcGIS.</p>
</li>
</ol>
<h1 id="map-batching-template">Map batching template</h1>
<p>Making maps quickly and automatically is essential. </p>
<p>Imagine a map production task for a paper. Apart from the initial cartographic process, there will be legitimate, repeat requests to adjust layout, styles, and <em>minor</em> details that entail massive changes, unknown except to the author of the map. Additionally, such adjustments usually involve multiple maps. Finally when it comes to printing or publishing, it is quite common to expect a different format  or a number of formats. The time and efforts required to address these challenges are not trivial but they tend to go unnoticed and under appreciated.</p>
<p>I'd like to automate this process as much as possible and reduce workload, therefore I created templates specifically to address the two broad scenarios below:</p>
<ol>
<li>from an ArcGIS Map Document (mxd file) to an exported map of a given format (e.g. pdf file). This is identical to clicking the export button and specify some export parameters.</li>
<li>from a single Map Document to a series of maps. Typically, each iteration/ feature of a dataset will result in a separate map.</li>
</ol>
<p>The underlying technical solution to the above two scenarios involves the <code>Yichuan10.ExportMXDtoMap</code> function, which is a thin, convenient wrapper around built-in map functions in the <code>arcpy.mapping</code> module. </p>
<p>The process usually involves the below steps:</p>
<ol>
<li>pre-author a map (no need to turn on data driven pages)</li>
<li>ensure there is an index layer with id. They need to be specified and referenced in the map template (only applies to the second scenario).</li>
</ol>
<p>One common task in the first scenario is to export a folder of MXD Map Documents, repeatedly with multiple formats. This could be easily achieved with a loop. </p>
<p>Here is an <a href="https://github.com/Yichuans/geoprocessing/blob/master/mapbatch/batch_map_mxd_folders_publish.py">example</a> to export from a Map Document to a thumbnail, a map for web, and a map for use in Adobe Illustrator (AI format, for further editing and publication).</p>
<p>The second scenario requires a loop to go through the feature class. Depending on its attributes or geometry, the map will then be different. For instance, difference can reflect in the title, extent indicator, spatial reference or on/off of a particular layer. For example, a scenario may be to create a map per species or per protected areas. In this case, the task is less flexible and needs to be adapted to account for unique requirements that cannot be fully captured in a single, reusable template.</p>
<p>For example, the <a href="https://github.com/Yichuans/geoprocessing/blob/master/mapbatch/mapbatcher_simple.py">simple map batcher</a> sets a definition query, a spatial reference, scale/extent, and then exports a jpg format map with a select resolution. The snippet for the above steps is listed below</p>
<pre><code class="python">exportpng = exportfolder + os.sep + str(each) + '.jpg'

query = '\&quot;wdpaid\&quot; = ' + str(each)

# only the above wdpaid feature visible
layer_index.definitionQuery = query

# set dataframe coordinate system
sr =arcpy.SpatialReference()

sr_string = Yichuan10.GetFieldValueByID_mk2(layer_index, each, value_field='utm')

sr.loadFromString(sr_string)

# load from its attribute
df.spatialReference = sr

df.extent = layer_index.getExtent()
df.scale = df.scale * 1.1

# need to specify a low quality
arcpy.mapping.ExportToJPEG(mxd, exportpng, &quot;PAGE_LAYOUT&quot;, resolution = reso, jpeg_quality=60)
</code></pre>

<p>N.B. at the end of each iteration, it is good practice to clear the definition query by assigning its value to 'empty' (e.g. in the above case, <code>layer_index.definitionQuery = ''</code>)</p>
<p>Finally, it is not necessary to adapt the map batch template to automate the production of maps. ArcGIS has a built-in tool call <a href="http://desktop.arcgis.com/en/arcmap/10.3/map/page-layouts/what-are-data-driven-pages-.htm">data drive pages</a> or <a href="http://pro.arcgis.com/en/pro-app/help/layouts/map-series.htm">Map series</a> in ArcPro. Their use is beyond the scope of this handover to discuss. In my opinion, data drive pages do not give a fine control in terms of iteration, nor allow the level of customisation that I required for my map production process.</p>
<h1 id="richness-template">Richness template</h1>
<p>The origin of this template goes back to 2010 when I was tasked with calculating species richness (counting number of species) using the global hexagon grid. This forms part of the analysis published in the paper titled <a href="http://science.sciencemag.org/content/330/6010/1503">The Impact of Conservation on the Status of the World’s Vertebrates</a>. I re-wrote and improved in Python from the original code written in VBA (by Nick?).</p>
<p>The aim of the template is to simply count the number of overlaying species in each 'unit' for all units in the base layer, be it hexagons or protected areas. While conceptually simple, the implementation may not be straightforward. The beauty of this implementation in my opinion is two fold:</p>
<ol>
<li>only perform an intersection test</li>
<li>minimal information is recorded</li>
</ol>
<p>This means it does not require computationally intensive calculations of the actual intersections (for those who use PostGIS, think of <code>st_intersects</code> rather than <code>st_intersection</code>, see <a href="../st_intersects postgis">PostGIS documentation</a>), and it only records IDs, minimal information needed for subsequent analyses.</p>
<p>The current implementation relies on iterative <code>arcpy.SelectLayerByLocation_management</code> calls between a species layer and a base layer. For efficiency reasons, the species layer is created within each iteration by <code>arcpy.MakeFeatureLayer_management</code> with a given ID, and deleted after use; in contrast, the base layer is however re-used and resides in the memory persistently, until all iterations are complete. After the base layer is successfully 'selected', a data cursor loops through its records (when <code>GetUniqueValuesFromFeatureLayer_mk2</code> works on a feature layer with a selection, it will only work on the selected features) and saved as a list of ID strings (each representing a species and a base layer). It is formatted for eventual export to a csv file.</p>
<pre><code class="python">def species_richness_calculation(id, hexagonLyr):

    # make species layer
    if type(id) in [str, unicode]:
        exp = '\&quot;' + speciesID + '\&quot; = ' + '\'' + str(id) + '\''
    elif type(id) in [int, float]:
        exp = '\&quot;' + speciesID + '\&quot; = ' + str(id)
    else:
        raise Exception('ID field type error')

    # make layers
    arcpy.MakeFeatureLayer_management(speciesData, speciesLyr, exp)

    # select by locations
    arcpy.SelectLayerByLocation_management(hexagonLyr, overLapOption, speciesLyr)

    # record it
    hex_ids = GetUniqueValuesFromFeatureLayer_mk2(hexagonLyr, hexagonID)

    result = list()

    for hex_id in hex_ids:
        result.append(str(int(id)) + ',' + str(hex_id) + '\n')

    # get rid of layers
    arcpy.Delete_management(speciesLyr)

    return result
</code></pre>

<p>More recently, this template has been improved to utilise parallel processing to reduce time. ArcGIS cannot use more than one core at a time, so the challenge dictates dividing the task into smaller chunks for multiple ArcGIS processes, and then finally stitch together. The first parallel solution simply uses the <a href="#parallel-template">parallel template</a>, but later solutions incorporate further optimisations in the template to improve efficiency and add additional functionality. More specifically, it involves:</p>
<ol>
<li>Logger. Analysis with large, multi-source spatial data almost inevitably fail. Therefore it is often necessary to record failing features, investigate and then find specific solutions.</li>
<li>Move the making layer logic to the worker. Making layer is expensive (time-consuming) - it is much faster for each worker process to have a layer that they could readily re-use, without having to re-create for each iteration. It's a compromise between keeping task-specific logic from the multi-processing template and achieving better efficiency.</li>
</ol>
<p>Note the difference between the original worker function (below)</p>
<pre><code class="python">def worker(q, q_out):
    while True:
        # monitoring
        if q.qsize() %100 == 0:
            print 'Remaining jobs:', q.qsize()

        # get and ID from job id queue
        job_id = q.get()
        if job_id == 'STOP':
            break

        result = job(job_id)
        q_out.put(result)
</code></pre>

<p>and the adapted worker function. Note the position of <code>arcpy.MakeFeatureLayer_management</code> and <code>arcpy.Delete_management</code>, which would otherwise occur in the <code>species_richness_calculation</code> function.</p>
<pre><code class="python">def worker(q, q_out):
    # make layer here to reduce overhead
    arcpy.MakeFeatureLayer_management(hexagonData, hexagonLyr)

    while True:
        # monitoring
        if q.qsize() %100 == 0:
            print('Time:', datetime.datetime.now().time())
            print('Remaining jobs:', q.qsize())

        # get and ID from job id queue
        job_id = q.get()
        if job_id == 'STOP':
            break

        result = species_richness_calculation(job_id, hexagonLyr)
        q_out.put(result)

    arcpy.Delete_management(hexagonLyr)
</code></pre>

<p>The reduction in the time needed to undertake species richness analysis is significant - not quite linear reduction with the increase of CPU cores, but for my computer of 6 cores (12 threads) when using 10 worker process, it sees 7-8 times improvement. For example, the annual richness calculation itself for nomination + existing WH sites takes less than 3 hours, a previously unthinkable performance.</p>
<p>Furthermore, due to its generic use case, attempts are made to facilitate a uniform overlapping/binning process, with promising potentials.</p>
<p>For example, by running both the richness calculation between WDPA and the global hexagon grid, and between RedList and the global hexagon grid, the intersection between WDPA and RedList could be easily obtained by using the grid as a look up table. This eliminates the need for complicated spatial overlays. Any further calculations have now reduced to non-spatial tabulation/pivot tables. </p>
<p>The added benefits also include deferring decisions on groupings (for example, threatened species, or country/regional level statistics) towards a later time without re-doing the spatial overlay. This requires analysis be designed in the lowest possible granularity to enable later separation. </p>
<p>For example, if a decision to select species range based on presence, origin and seasonality is to be deferred, the analysis must use the row id (usual <code>fid</code>) instead of the species id <code>id_no</code>. This is because <code>id_no</code> will make no effort to separate between polygons with presence 1 or presence 2 - it only differentiates species</p>
<p>The <a href="http://nbviewer.jupyter.org/github/Yichuans/biodiversity-food-agriculture/blob/master/Biodiversity%20for%20food%20and%20agriculture.ipynb">biodiversity for food and agriculture analysis/BFA FAO analysis</a> is a good example with this thinking in mind (Here is <a href="https://github.com/Yichuans/geoprocessing/blob/master/species_richness/FAO_BFA.py">the script</a>)</p>
<h1 id="parallel-template">Parallel template</h1>
<p>The idea for this template comes from the need to speed up slow-running processes. In the old days, the richness calculation can be painstakingly fiddly and slow: cutting the tasks to smaller chunks to run over a number of machines over a number of days is not only a unpleasant experience nor a sustainable solution (and error prone!). Even with a small subset of protected areas, running richness for all Red List species remains a challenge. </p>
<p>One of the bottlenecks of performance is that ArcGIS Desktop uses one core at a time - it does not take advantage of the full computing capacity of modern multi-core computer architecture. The parallel template was then written as a way of using Python to deploy multiple ArcGIS processes to distribute workload automatically.</p>
<p>The process goes like this:</p>
<ol>
<li>Create an input pipe containing a list of unique IDs. Each ID represents a piece of data</li>
<li>Create an initially empty output pipe to host result (will come from the worker processes)</li>
<li>Create a number of worker processes, that actively get data from IDs in the input pipe</li>
<li>Create a worker process, that listens actively for incoming results from the output pipe and then processes them, for example write to an output file</li>
<li>The main function manages the pipes: distributes work, logs and waits for completion</li>
</ol>
<p><a href="https://github.com/Yichuans/geoprocessing/blob/master/snippet/multi_processing_template.py">This is the link to the template</a></p>
<p>Notably, it needs to add the text flag 'STOP' (or for that matter any flag would do as long as it is the same as what the worker process would watch out for) to the input queue.</p>
<pre><code class="python"># Add queue of a list of ids to process
q = get_queue()

# setup and run worker processes
p_workers = list()
for i in range(WORKER):
    print 'Starting worker process:', i
    p = multiprocessing.Process(target=worker, args=(q, q_out))
    p_workers.append(p)

# start
for p in p_workers:
    p.start()

# add stop flag to the queue
for p in p_workers:
    q.put('STOP')
</code></pre>

<p>The worker process remains alive until it sees the 'STOP' signal to terminate.</p>
<pre><code class="python">def worker(q, q_out):
    while True:
        # monitoring
        if q.qsize() %100 == 0:
            print 'Remaining jobs:', q.qsize()

        # get and ID from job id queue
        job_id = q.get()
        if job_id == 'STOP':
            break

        result = job(job_id)
        q_out.put(result)
</code></pre>

<h1 id="new-data-analysis-process">New data analysis process</h1>
<p>(It is not really 'new' - but I still have not seen a wide adoption of this novel process being applied in analyses at IUCN or WCMC)</p>
<p>This is an improved work flow that I find myself increasingly using. Typically it begins with a spatial analysis, but only once. All subsequent analyses and visualisation then take place within a <a href="http://jupyter.org">Jupyter notebook</a>. For routine analyses, this process seems to work very well, as long as the initial spatial analysis is designed in such a way (with the smallest granularity) that allow further interrogation of data with non-spatial analyses.</p>
<p>The benefits of this process:</p>
<ol>
<li>less error prone as a result from spatial analysis. Spatial analysis is done only once at the smallest granularity</li>
<li>further questions of different aggregations can be answered with a non-spatial analysis (as long as the scale is higher than what's used in the spatial analysis)</li>
<li>methodology is fully open, and reproducible with little effort (apart from the initial spatial analysis)</li>
<li>the entire analytical process: data cleaning, analysis, and visualisation is fully documented and can easily be shared</li>
</ol>
<p>Example analyses:</p>
<ol>
<li><a href="http://nbviewer.jupyter.org/github/yichuans/climate-vulnerable-wh/blob/master/workspace.ipynb">Climate change vulnerability analysis</a> and the <a href="http://nbviewer.jupyter.org/github/yichuans/climate-vulnerable-wh/blob/master/report.ipynb">writing of report</a></li>
<li><a href="http://nbviewer.jupyter.org/github/yichuans/world-heritage-outlook-analysis/blob/master/analysis.ipynb">World Heritage Outlook 2 analysis</a></li>
<li><a href="http://nbviewer.jupyter.org/github/yichuans/biodiversity-food-agriculture/blob/master/Biodiversity%20for%20food%20and%20agriculture.ipynb">Biodiversity for food and agriculture</a></li>
<li><a href="http://nbviewer.jupyter.org/github/yichuans/wilderness-wh/blob/master/wilderness_analysis.ipynb">Wilderness analysis</a> and the <a href="http://nbviewer.jupyter.org/github/yichuans/wilderness-wh/blob/master/WH%20marine%20wilderness%20methodology.ipynb">writing of methodology</a></li>
<li><a href="http://nbviewer.jupyter.org/github/yichuans/icca-study/blob/master/analysis.ipynb">ICCA species richness</a></li>
</ol>
<h1 id="arcgis-and-anaconda">ArcGIS and Anaconda</h1>
<p>Of course, there is no reason why the spatial analysis should be excluded from the above process. Thus, the entire work flow of reading data, performing analysis and exporting or visualising results could be theoretically included in a single workspace such as a Jupyter notebook. </p>
<p>The main challenge is for the Python and its libraries to talk to ArcGIS and vice versa. The problem is that ArcGIS uses a specific version of Python and its numerical libraries, which cannot be updated without breaking the ArcGIS installation (when using <code>arcpy</code> for example).</p>
<p><a href="https://www.anaconda.com">Anaconda</a>, a popular Python data science platform, can be used to create an environment to satisfy a specific installation of ArcGIS with compatible versions of other libraries.</p>
<p>USGS has a useful guide on <a href="https://my.usgs.gov/confluence/display/EGIS/Using+Anaconda+modules+from+the+ESRI+python+environment">how to use anaconda modules from the esri Python environment</a> to set up such a environment.</p>
<p>Lastly, this may work for small spatial analyses, however, I would argue for the geoprocessing I require (takes hours or even days) this may not be a good idea. Such analyses tend to fail a couple of times and require significant back and forth experimenting and fixing of data manually - these would be better off dealt with separately.</p>
<p>I adapted a <a href="https://github.com/Yichuans/geoprocessing/blob/master/usercustomize.py">customised script</a> (authored by <a href="mailto:cprice@usgs.gov">Curtis Price</a>) for my system to connect ArcGIS and Anaconda</p>
<h1 id="miscellaneous">Miscellaneous</h1>
<p>(TBA)</p>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../comparative-analysis/" title="Comparative analysis" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Comparative analysis
              </span>
            </div>
          </a>
        
        
          <a href="../world-heritage-knowledge-lab/" title="World Heritage Analyses" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                World Heritage Analyses
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.f041762f.js"></script>
      
      <script>app.initialize({version:"0.17.2",url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>